{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4754a3e",
   "metadata": {},
   "source": [
    "# Python applications to visualise 2D subsurface geoscience data\n",
    "\n",
    "## A Case Study on coalmines dataset from Ruhr coalfield in the lower Rhine basin, Germany.  \n",
    "\n",
    "***By: Ramy Abdallah***\n",
    "\n",
    "![Thrust Faults Structures](https://i.imgur.com/x2C3zud.jpg)\n",
    "Source of image: https://www.alamy.com/variscan-fault-propagation-fold-at-broadhaven-pembrokeshire-image60538849.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cbf641",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ee04f",
   "metadata": {},
   "source": [
    "Visualising 2D subsurface models and data in-depth domain is the first step in structural analysis approaches using Python. Subsurface models visualisation is critical in structural interpretations, such as mapping water aquifers, top hydrocarbons reservoirs, coal layers, or C2 storage in deep underground rock formations. While professional toolkits such as Move, OpendTect and Petrel require commercial licences or have a limited edition and availability of academic licences, Python can provide a free and robust environment that can visualise, process and interpret these subsurface data. However, our first challenge is to visualise these 2D subsurface models. Here our structural analysis will be to calculate the displacement offsets automatically from these subsurface models. This notebook will focus on visualising our 2D subsurface data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7067141c",
   "metadata": {},
   "source": [
    "The 2D subsurface models can be complex and reflect thrusts, synclines and anticlines structures. Here we show a complex cross-section of the Ruhr coalfield. \n",
    "\n",
    "![Thrust Faults Structures](https://i.imgur.com/HNzviLJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b67dd",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626a4315",
   "metadata": {},
   "source": [
    "Our main objective is to visualise our 2D subsurface models using free Python libraries. These include visualising faults and horizons and all related vertical and horizontal wells. Our automated approach is based on a Python script and can be applied to similar datasets where 2D subsurface data models need to be visualised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33052767",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c4fea",
   "metadata": {},
   "source": [
    "Our dataset consists of two types of files CSV and Data files as follows: \n",
    "\n",
    ">1. CSV file contains the data for the 2D subsurface models as faults, horizons and wells.\n",
    ">2. Data file contains the data for the 2D subsurface models as faults, horizons and wells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f482bc5",
   "metadata": {},
   "source": [
    "Before we start our visualisation, let us import all the needed libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb36f8",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9916bf",
   "metadata": {},
   "source": [
    "In this study we are going to use mainly `plotly`, `matplotlib` and `seaborn` libarary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1be84",
   "metadata": {},
   "source": [
    "#### Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443fdca6",
   "metadata": {},
   "source": [
    "The Python graphing package from `Plotly` creates interactive, publication-quality graphs. Line plots, scatter plots, area charts, bar charts, error bars, box plots, histograms, heatmaps, subplots, multiple-axes, polar charts, and bubble charts are all examples of how to build them.\n",
    "Plotly.py is open source and free to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb952e25",
   "metadata": {},
   "source": [
    "For more information see https://plotly.com/python/\n",
    "\n",
    "Also, see `plotly.express` https://plotly.com/python/plotly-express/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9adbd5",
   "metadata": {},
   "source": [
    "#### Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9de5bf",
   "metadata": {},
   "source": [
    "`Matplotlib` is a Python package that allows you to create static, animated, and interactive visualisations. Matplotlib makes simple things simple and difficult things possible.\n",
    "\n",
    "For more information see https://matplotlib.org/stable/users/getting_started/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb195e4",
   "metadata": {},
   "source": [
    "#### Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eb5670",
   "metadata": {},
   "source": [
    "`Seaborn` is a matplotlib-based Python data visualisation package. It offers a high-level interface for creating visually appealing and useful statistics visuals.\n",
    "\n",
    "For more information see https://seaborn.pydata.org/#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b43c4",
   "metadata": {},
   "source": [
    "Also, we import a few other modules to make our plots looks professional such as `PyQt5`. Please see https://doc.qt.io/qtforpython/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import plotly.offline\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px\n",
    "from PyQt5.QtCore import QUrl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from PyQt5.QtWidgets import QApplication\n",
    "from PyQt5.QtWebEngineWidgets import QWebEngineView\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1143b61",
   "metadata": {},
   "source": [
    "## Project Generalised Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9087d83",
   "metadata": {},
   "source": [
    ">1. **Load, read and explore the data**\n",
    ">2. **Perform data preparation & cleaning**\n",
    ">3. **2D visualization of the subsurface models**\n",
    ">4. **Summarize inferences & write a conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb9df5",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e03ad2",
   "metadata": {},
   "source": [
    "### 1. Load, read and explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308bfc8e",
   "metadata": {},
   "source": [
    "#### Download Geological Models as CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbce1206",
   "metadata": {},
   "source": [
    "Let us get started by creating a dataframes, where we read the csv file into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0741f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_df_all = pd.read_csv(r'C:\\Users\\r04ra18\\Desktop\\fault-dataset-and-chapter-8\\final-notebooks\\data\\hor_all_model.csv')\n",
    "\n",
    "oc1_df = pd.read_csv(r'C:\\Users\\r04ra18\\Desktop\\fault-dataset-and-chapter-8\\final-notebooks\\data\\oc1.csv')\n",
    "\n",
    "tw1_df = pd.read_csv(r'C:\\Users\\r04ra18\\Desktop\\fault-dataset-and-chapter-8\\final-notebooks\\data\\tw_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103cf63e",
   "metadata": {},
   "source": [
    "Let us explore the dataframe and get some basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5fb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b319cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec93faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08bde7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d3ce4",
   "metadata": {},
   "source": [
    "### 2. Data preparation & cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302d90d",
   "metadata": {},
   "source": [
    "#### Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f405e",
   "metadata": {},
   "source": [
    "Let us check if there are any null values in our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1462a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_df_all.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d762c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc1_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b928a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw1_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01baf4f8",
   "metadata": {},
   "source": [
    "#### Duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9f612",
   "metadata": {},
   "source": [
    "Let us check if there are any duplicates values in our models and try to drop theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_df_all.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b00696",
   "metadata": {},
   "source": [
    "So we have 4 datapoints that are duplicated in our horizons and faults dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc1_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ae399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tw1_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552ee7c",
   "metadata": {},
   "source": [
    "Let us drop the duplicated data and return DataFrame with duplicate rows removed.\n",
    "\n",
    "Considering certain columns as \"x\", \"y\" and \"z\".And let us keep the last value and drop the first value of the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_df_all.drop_duplicates(subset=['x', 'y', 'z'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc1_df.drop_duplicates(subset=['x', 'y', 'z'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw1_df.drop_duplicates(subset=['x', 'y', 'z'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d317124f",
   "metadata": {},
   "source": [
    "### 3. 2D Geological Model Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ced6a2",
   "metadata": {},
   "source": [
    "We can visualise the 2D model using `plotly.express` as follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hor_df_all, x=hor_df_all['x'], y=hor_df_all['z'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542f65b",
   "metadata": {},
   "source": [
    "Moreover, we can visualise our 2D subsurface models in a separate window for better visualisation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5fe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "x0 = hor_df_all['x']\n",
    "z0 = hor_df_all['z']\n",
    "\n",
    "\n",
    "x1 = oc1_df['x']\n",
    "z1 = oc1_df['z']\n",
    "\n",
    "x2 = tw1_df['x']\n",
    "z2 = tw1_df['z']\n",
    "\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter traces\n",
    "fig.add_trace(go.Scatter(x=x0, y=z0, name=\"Coal Layers\", mode=\"markers\"))\n",
    "fig.add_trace(go.Scatter(x=x1, y=z1, name=\"Outcrops\", mode=\"markers\", marker_color='gray'))\n",
    "fig.add_trace(go.Scatter(x=x2, y=z2, name=\"Boreholes\", mode=\"lines+markers\", marker_color='black'))\n",
    "\n",
    "fig.update_layout(showlegend=True)\n",
    "\n",
    "def show_in_window(fig):\n",
    "   \n",
    "    plotly.offline.plot(fig, filename='name.html', auto_open=False)\n",
    "    \n",
    "    app = QApplication(sys.argv)\n",
    "    web = QWebEngineView()\n",
    "    file_path = os.path.abspath(os.path.join('.', \"name.html\"))\n",
    "    web.load(QUrl.fromLocalFile(file_path))\n",
    "    web.show()\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "\n",
    "show_in_window(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac6765",
   "metadata": {},
   "source": [
    "The result will be displayed in a separate window. However, we provide an image for the result like the following image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc38404",
   "metadata": {},
   "source": [
    "![Visualisation of Coal layers 2D model](https://i.imgur.com/7dJWbrJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e16368",
   "metadata": {},
   "source": [
    "Now, after visualising the basic model, let us try to visualise our models and distinguish between the horizons, faults and wells information. Here we will use a CSV file with more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(r'C:\\Users\\r04ra18\\Desktop\\fault-dataset-and-chapter-8\\final-notebooks\\data\\surface-model-data-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data_df, x=data_df['x'], y=data_df['z'], color=data_df['Name'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf087ea",
   "metadata": {},
   "source": [
    "Let us now separate the wells, horizons, fault data from the horizons data. First we will start with the verticcal and horizontal wells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3181a",
   "metadata": {},
   "source": [
    "Here we create a dataframe for the wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a7ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_df = data_df[data_df['Name'] == 'Well']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9485a4b",
   "metadata": {},
   "source": [
    "Using the info from the well ids we can differentiate between the wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eca86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_df['Id'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ffa6b",
   "metadata": {},
   "source": [
    "Then we get the number of the wells and store it in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_ls = well_df['Id'].unique().tolist()\n",
    "wells_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ba453",
   "metadata": {},
   "source": [
    "We have 11 wells with different ids. Now, let us separate each well into a different dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a951230",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_0 = well_df[well_df['Id'] == wells_ls[0]]\n",
    "well_1 = well_df[well_df['Id'] == wells_ls[1]]\n",
    "well_2 = well_df[well_df['Id'] == wells_ls[4]]\n",
    "well_3 = well_df[well_df['Id'] == wells_ls[5]]\n",
    "well_4 = well_df[well_df['Id'] == wells_ls[6]]\n",
    "well_5 = well_df[well_df['Id'] == wells_ls[7]]\n",
    "well_6 = well_df[well_df['Id'] == wells_ls[8]]\n",
    "well_7 = well_df[well_df['Id'] == wells_ls[9]]\n",
    "well_8 = well_df[well_df['Id'] == wells_ls[10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ab297",
   "metadata": {},
   "source": [
    "Let us ope well number 6 and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe124c",
   "metadata": {},
   "source": [
    "Second, let us separate the outcrop data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcrop_df = data_df[data_df['Name'] == 'outcrop-1']\n",
    "outcrop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdda717",
   "metadata": {},
   "source": [
    "After this let us display the wells and outcrops data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_scatter(x=well_0['x'], y=well_0['z'], mode = 'markers+lines', name='well-1')\n",
    "fig.add_scatter(x=well_1['x'], y=well_1['z'], mode = 'markers+lines', name='well-2')\n",
    "fig.add_scatter(x=well_2['x'], y=well_2['z'], mode = 'markers+lines', name='well-3')\n",
    "fig.add_scatter(x=well_3['x'], y=well_3['z'], mode = 'markers+lines', name='well-4')\n",
    "fig.add_scatter(x=well_4['x'], y=well_4['z'], mode = 'markers+lines', name='well-5')\n",
    "fig.add_scatter(x=well_5['x'], y=well_5['z'], mode = 'markers+lines', name='well-6')\n",
    "fig.add_scatter(x=well_6['x'], y=well_6['z'], mode = 'markers+lines', name='well-7')\n",
    "fig.add_scatter(x=well_7['x'], y=well_7['z'], mode = 'markers+lines', name='well-8')\n",
    "fig.add_scatter(x=well_8['x'], y=well_8['z'], mode = 'markers+lines', name='well-9')\n",
    "fig.add_scatter(x=outcrop_df['x'], y=outcrop_df['z'], mode = 'markers', name='Outcrop')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81baef64",
   "metadata": {},
   "source": [
    "Lastly, let us get the horizons data in the same way. Looking at the unnique horizons and there numbers and names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e217c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Horizon.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Horizon.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254df5f7",
   "metadata": {},
   "source": [
    "We have 7 horizons in our subsurface model with 34 horizons name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b39cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d79b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd67278",
   "metadata": {},
   "source": [
    "In this step we take out the names that they are not horizons names and take it out from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_hor_ls = ['Line', 'Well', 'Tunnel_Well', 'Fold_1_1', 'Fold_1_2', 'Fold_1_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_all_df = data_df[~data_df.Name.isin(not_hor_ls)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_all_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5d65a",
   "metadata": {},
   "source": [
    "Finally, we create a small function to clean the dataframe and sellect just the \"x\" and \"y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd6e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_xz(df):\n",
    "    df1 = df[['x','z']]\n",
    "    df2 = df1[df1.duplicated()]\n",
    "    df3 = df2.drop_duplicates()\n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7cffef",
   "metadata": {},
   "source": [
    "Then we apply the fuction to the dataframe to create a new clean dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_clean_df = select_xz(hor_all_df)\n",
    "hor_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2434226e",
   "metadata": {},
   "source": [
    "After cleaning and get the horizons data let us visulaise out subsurface model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcaa657",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hor_clean_df, x=hor_clean_df['x'], y=hor_clean_df['z']).update_traces(marker=dict(color='green'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238f2eb",
   "metadata": {},
   "source": [
    "We can also use `matplotlib` to visualise our 2D subsurface model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e98ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "im = plt.scatter(x=hor_clean_df['x'], y=hor_clean_df['z'])\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"z\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21422346",
   "metadata": {},
   "source": [
    "Finally, we can plot all our data to visualise the subsurface model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add horizons\n",
    "fig.add_scatter(x=hor_clean_df['x'], y=hor_clean_df['z'], mode = 'markers', name='Horizons', marker_color='green')\n",
    "\n",
    "# Add outcrops\n",
    "fig.add_scatter(x=outcrop_df['x'], y=outcrop_df['z'], mode = 'markers', name='Outcrops')\n",
    "\n",
    "# Add wells\n",
    "fig.add_scatter(x=well_0['x'], y=well_0['z'], mode = 'markers+lines', name='well-1')\n",
    "fig.add_scatter(x=well_1['x'], y=well_1['z'], mode = 'markers+lines', name='well-2')\n",
    "fig.add_scatter(x=well_2['x'], y=well_2['z'], mode = 'markers+lines', name='well-3')\n",
    "fig.add_scatter(x=well_3['x'], y=well_3['z'], mode = 'markers+lines', name='well-4')\n",
    "fig.add_scatter(x=well_4['x'], y=well_4['z'], mode = 'markers+lines', name='well-5')\n",
    "fig.add_scatter(x=well_5['x'], y=well_5['z'], mode = 'markers+lines', name='well-6')\n",
    "fig.add_scatter(x=well_6['x'], y=well_6['z'], mode = 'markers+lines', name='well-7')\n",
    "fig.add_scatter(x=well_7['x'], y=well_7['z'], mode = 'markers+lines', name='well-8')\n",
    "fig.add_scatter(x=well_8['x'], y=well_8['z'], mode = 'markers+lines', name='well-9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3ced7",
   "metadata": {},
   "source": [
    "We can also adjust the colours to make our plot look more professinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf65620",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add horizons\n",
    "fig.add_scatter(x=hor_clean_df['x'], y=hor_clean_df['z'], mode = 'markers', name='Horizons', marker_color='green', opacity=0.3)\n",
    "\n",
    "# wells\n",
    "fig.add_scatter(x=well_0['x'], y=well_0['z'], mode = 'markers+lines', name='well-1')\n",
    "fig.add_scatter(x=well_1['x'], y=well_1['z'], mode = 'markers+lines', name='well-2')\n",
    "fig.add_scatter(x=well_2['x'], y=well_2['z'], mode = 'markers+lines', name='well-3')\n",
    "fig.add_scatter(x=well_3['x'], y=well_3['z'], mode = 'markers+lines', name='well-4')\n",
    "fig.add_scatter(x=well_4['x'], y=well_4['z'], mode = 'markers+lines', name='well-5')\n",
    "fig.add_scatter(x=well_5['x'], y=well_5['z'], mode = 'markers+lines', name='well-6')\n",
    "fig.add_scatter(x=well_6['x'], y=well_6['z'], mode = 'markers+lines', name='well-7')\n",
    "fig.add_scatter(x=well_7['x'], y=well_7['z'], mode = 'markers+lines', name='well-8')\n",
    "fig.add_scatter(x=well_8['x'], y=well_8['z'], mode = 'markers+lines', name='well-9')\n",
    "\n",
    "#############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d9631",
   "metadata": {},
   "source": [
    "BY this we learn how to visualise our subsurface data in 2D plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d19d6d",
   "metadata": {},
   "source": [
    "#### Download Geological Models as Data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1b849",
   "metadata": {},
   "source": [
    "Here we use data file format to visualise our subsurface model in 2D plot. First we create a file path then opens the file at given filepath and read all lines from file, then store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d242a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'C:\\Users\\r04ra18\\Desktop\\fault-dataset\\final-notebooks\\data\\fault_model_13012020.dat'\n",
    "\n",
    "with open(filepath, \"r\") as file:\n",
    "    lines = file.readlines()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0ca1f",
   "metadata": {},
   "source": [
    "Let us print the number of lines and the first 10 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of lines:\", len(lines), \"\\n\")\n",
    "print(\"first 10 lines:\\n\")\n",
    "lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fce8a5",
   "metadata": {},
   "source": [
    "In this step we iterate over every line and strip away the `\\n`, `\\tFault` and `\\tHorizon_10` from the right of the string from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa845b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(lines):   \n",
    "    lines[i] = line.rstrip(\"\\n\").rstrip(\"\\tFault\").rstrip(\"\\tHorizon_03\").rstrip(\"\\tHorizon_05\").rstrip(\"\\tHorizon_07\").rstrip(\"\\tHorizon_10\")\n",
    "    \n",
    "lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb396794",
   "metadata": {},
   "source": [
    "Let drop the first and last text lines in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d72da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_header = lines[:1]\n",
    "file_grid = lines[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79247a4e",
   "metadata": {},
   "source": [
    "Now let us create a loop to iterate over the data and clean out `\\t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_values = []  \n",
    "for line in file_grid:  \n",
    "    line_values = line.split(\"\\t\") \n",
    "                                   \n",
    "    for xyz_value in line_values: \n",
    "        xyz_values.append(float(xyz_value))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302abc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xyz_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b7256",
   "metadata": {},
   "source": [
    "After that, let us get the ‘x’, ‘y and ‘z’ values from the data and store them in different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_values\n",
    "x = xyz_values[::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12651f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_values\n",
    "y = xyz_values[1::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83210a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_values\n",
    "z = xyz_values[2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5fffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"x\" : x, \"y\" : y, \"z\" : z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(d, columns=[\"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1078a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8955555",
   "metadata": {},
   "source": [
    "We use `matplotlib` to visualise our subsurface modles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "im = plt.scatter(x, z, c=y)\n",
    "\n",
    "plt.colorbar(im, label=\"y-values\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"z\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fa8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "im = plt.scatter(x, z, c=y, cmap=\"magma\")\n",
    "\n",
    "plt.colorbar(im, label=\"y-values\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"z\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da54376",
   "metadata": {},
   "source": [
    "We also can change the colours from the folowing list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_ls = ['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', \n",
    "            'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', \n",
    "            'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', \n",
    "            'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', \n",
    "            'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', \n",
    "            'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', \n",
    "            'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', \n",
    "            'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', \n",
    "            'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', \n",
    "            'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', \n",
    "            'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', \n",
    "            'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', \n",
    "            'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', \n",
    "            'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', \n",
    "            'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', \n",
    "            'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', \n",
    "            'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', \n",
    "            'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', \n",
    "            'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', \n",
    "            'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48788083",
   "metadata": {},
   "source": [
    "Finally, let us visualise our 2D subsurface data model with suitable colours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6795173",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "im = plt.scatter(x, z, c=y, cmap=\"viridis\")\n",
    "\n",
    "plt.colorbar(im, label=\"y-values\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"z\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac836b1",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7684e3b",
   "metadata": {},
   "source": [
    "1. We visualise our 2D subsurface models using CSV and Data files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9682b",
   "metadata": {},
   "source": [
    "2. We clean, prepare and separate our subsurface data to plot the horizons, faults and wells in 2D plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb666e",
   "metadata": {},
   "source": [
    "3. We explore several ways to visualise the subsurface data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57a5118",
   "metadata": {},
   "source": [
    "4. We recommend using the `plotly` library to visualise the subsurface data for best visualisation of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488570b8",
   "metadata": {},
   "source": [
    "5. However, `matplotlib` express faster, easier and lighter approach for visualisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb372a",
   "metadata": {},
   "source": [
    "6. We will be using `matplotlib` library to calculate the displacement offsets in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e3e966",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/0qMxtSl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a785bfe",
   "metadata": {},
   "source": [
    "***Thank you!***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_comp",
   "language": "python",
   "name": "ml_comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
